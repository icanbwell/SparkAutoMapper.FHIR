from __future__ import annotations
from typing import Optional, TYPE_CHECKING, Union

# noinspection PyPackageRequirements
from pyspark.sql.types import StructType, DataType
from spark_auto_mapper_fhir.fhir_types.list import FhirList
from spark_auto_mapper_fhir.complex_types.meta import Meta
from spark_auto_mapper_fhir.extensions.extension_base import ExtensionBase
from spark_auto_mapper_fhir.fhir_types.id import FhirId

from spark_auto_mapper_fhir.base_types.fhir_resource_base import FhirResourceBase
from spark_fhir_schemas.r4.resources.parameters import ParametersSchema

if TYPE_CHECKING:
    pass
    # parameter (Parameters.Parameter)
    from spark_auto_mapper_fhir.backbone_elements.parameters_parameter import (
        ParametersParameter,
    )


# This file is auto-generated by generate_classes so do not edit manually
# noinspection PyPep8Naming
class Parameters(FhirResourceBase):
    """
    Parameters
    """

    # noinspection PyPep8Naming
    def __init__(
        self,
        *,
        id_: FhirId,
        meta: Optional[Meta] = None,
        extension: Optional[FhirList[ExtensionBase]] = None,
        parameter: Optional[FhirList[ParametersParameter]] = None,
    ) -> None:
        """

        :param id_: id of resource
        :param meta: Meta
        :param extension: extensions
        :param parameter: A parameter passed to or received from the operation.
        """
        super().__init__(
            resourceType="Parameters",
            id_=id_,
            meta=meta,
            extension=extension,
            parameter=parameter,
        )

    def get_schema(
        self, include_extension: bool
    ) -> Optional[Union[StructType, DataType]]:
        return ParametersSchema.get_schema(include_extension=include_extension)
